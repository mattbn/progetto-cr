{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMtT6q0Zd1nb0R/imxyN3Fv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modello di ML per il riconoscimento di cifre scritte a mano\n",
        "\n",
        "#### *(Comparazione delle performance di CPU, GPU e TPU)*\n",
        "\n",
        "Progetto per l'esame di Calcolatori Elettronici e Reti di Calcolatori\n",
        "\n",
        "I dati utilizzati nel seguente modello sono disponibili come dataset attraverso la API `tensorflow.keras.datasets` sotto la rispettiva licenza (come indicato [qui](https://keras.io/api/datasets/mnist/)).\n"
      ],
      "metadata": {
        "id": "jb-mTI0gNjee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inclusione librerie\n",
        "Come prima cosa, bisogna importare le librerie [numpy](https://numpy.org), [tensorflow](https://www.tensorflow.org) e [tensorflow_datasets](https://www.tensorflow.org/datasets):"
      ],
      "metadata": {
        "id": "a4a7MGg_OXzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import time # usato per ottenere misure accurate del tempo di esecuzione dei vari passi"
      ],
      "metadata": {
        "id": "GEOwnRs_OrzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Di seguito è definita una classe per la misura del tempo dei vari passi"
      ],
      "metadata": {
        "id": "W4oEQjGbO1ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# la classe è strutturata in questo modo per funzionare con i with statement\n",
        "class timer:\n",
        "  def __init__(self, enter_fn=None, exit_fn=None):\n",
        "    self.enter_fn = enter_fn\n",
        "    self.exit_fn = exit_fn\n",
        "  \n",
        "  def __enter__(self):\n",
        "    self.begin = time.perf_counter()\n",
        "    self.end = self.begin\n",
        "    if self.enter_fn:\n",
        "      self.enter_fn(self.begin)\n",
        "    return lambda: self.end - self.begin\n",
        "  \n",
        "  def __exit__(self, exc_type, exc_data, exc_tb):\n",
        "    self.end = time.perf_counter()\n",
        "    if self.exit_fn:\n",
        "      self.exit_fn(self.begin, self.end)\n",
        "  \n"
      ],
      "metadata": {
        "id": "yt6WUtqjO40T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A questo punto è opportuno scegliere alcune impostazioni per l'esecuzione, tra cui il <ins>**runtime**</ins> (selezionabile dalle impostazioni di Colab), il <ins>**numero di comparazioni di test**</ins> da eseguire alla fine (per verificare la correttezza delle previsioni del modello), il <ins>**numero di `epochs`**</ins> (ovvero il numero di iterazioni di allenamento) e la <ins>**batch_size**</ins> (ovvero la dimensione dei dati in input per ogni iterazione):"
      ],
      "metadata": {
        "id": "DPblnfpyPbL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Impostazioni\n",
        "\n",
        "#@markdown Numero di comparazioni di test:\n",
        "comparison_count = 400 #@param {type:\"slider\", min:100, max:1000, step:10}\n",
        "epoch_count = 10 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "batch_size = 400 #@param {type:\"slider\", min:100, max:1000, step:50}\n",
        "#@markdown Selezionare il parametro seguente se si desidera utilizzare delle GPU:\n",
        "use_gpu = True #@param {type:\"boolean\"}\n",
        "\n",
        "# riconoscimento runtime e selezione strategy adeguata\n",
        "strategy = tf.distribute.get_strategy()\n",
        "device_type = \"CPU\"\n",
        "\n",
        "# https://stackoverflow.com/a/62729266\n",
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(resolver)\n",
        "  device_type = \"TPU\"\n",
        "except ValueError:\n",
        "  # https://stackoverflow.com/a/38019608\n",
        "  device_list = tf.config.list_logical_devices(\"GPU\")\n",
        "  if use_gpu and len(device_list) > 0:\n",
        "    strategy = tf.distribute.MirroredStrategy(device_list)\n",
        "    device_type = \"GPU\"\n",
        "\n",
        "print(\"Dispositivi: \", tf.config.list_logical_devices(device_type))\n"
      ],
      "metadata": {
        "id": "G6hoIp8GzEuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Caricamento del dataset\n",
        "In questo caso viene usato il dataset MNIST fornito dalla libreria `tensorflow_datasets` contenente tutti i dati necessari per questo modello.\n",
        "I dati vengono caricati separatamente in due datasets contenenti rispettivamente delle immagini (con le relative label) per l'allenamento e per il testing della rete."
      ],
      "metadata": {
        "id": "QeIQimpWVCst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# caricamento dei dati\n",
        "# dividendo per 255 si ottiene un intervallo tra 0 e 1 per le intensità del grigio\n",
        "# per ogni immagine (e lo si trasforma in float)\n",
        "def scale(img, lab):\n",
        "  img = tf.cast(img, tf.float32)\n",
        "  img /= 255.0\n",
        "  return img, lab\n",
        "\n",
        "with timer() as load_time:\n",
        "  train_data, test_data = tfds.load(\n",
        "      'mnist', # nome del dataset da caricare\n",
        "      split=['train', 'test'], # insiemi di dati da caricare (allenamento e testing)\n",
        "      as_supervised=True, # carica anche le labels delle immagini\n",
        "      try_gcs=True # cerca il dataset su bucket GCS in modo da ottimizzare l'accesso per le TPU\n",
        "  )\n",
        "\n",
        "  train_data = train_data.map(scale).batch(batch_size) # scala e separa in batch\n",
        "  test_data = test_data.map(scale).batch(batch_size)\n"
      ],
      "metadata": {
        "id": "uDhnDPjrVWsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora che i dati sono stati caricati, è possibile passare alle operazioni sul modello."
      ],
      "metadata": {
        "id": "PhuDVL3RgXxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creazione del modello\n",
        "La creazione del modello viene effettuata mediante la API [Keras](https://keras.io):"
      ],
      "metadata": {
        "id": "nkeVlG0Lg9VP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with timer() as compilation_time:\n",
        "  with strategy.scope():\n",
        "    # crea una rete a 3 layer:\n",
        "    # 1 - input layer: trasforma l'immagine in un array\n",
        "    # 2 - hidden layer: composto da 128 unità, applica la funzione di attivazione (relu) e ne bilancia i pesi\n",
        "    # 3 - output layer: restituisce 10 valori contenenti le probabilità per ogni cifra\n",
        "    model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
        "      tf.keras.layers.Dense(128, activation='relu'), \n",
        "      tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "    # compilazione del modello\n",
        "    model.compile(\n",
        "        optimizer='sgd', \n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "        metrics=['sparse_categorical_accuracy'])\n",
        "  "
      ],
      "metadata": {
        "id": "my4j9_0uhJUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il metodo `tf.keras.Sequential` effettua la creazione della rete, prendendo come argomenti una lista di layers specificata dall'utente:\n",
        " - `tf.keras.layers.Flatten` si occupa esclusivamente di trasformare le immagini (che sono array bidimensionali 28x28) in array unidimensionali a 784 ($28^{2}$) elementi;\n",
        " - `tf.keras.layers.Dense` crea un layer che esegue una specifica funzione di attivazione (in questo caso **ReLU** per il layer intermedio (ovvero un [rettificatore](https://it.wikipedia.org/wiki/Rettificatore_(reti_neurali)), $f(x) = max(0,x)$) e nessuna per il layer di uscita;\n",
        "---\n",
        "Il metodo `compile` effettua la compilazione del modello, usando i parametri specificati dall'utente:\n",
        " - `optimizer` indica la funzione usata per l'ottimizzazione dell'uscita della rete (in questo caso è usata la funzione *SGD* che rappresenta la *discesa stocastica del gradiente*, che esamina il gradiente di un numero ristretto di campioni dei dati di input e ne valuta l'incremento basandosi sui parametri interni);\n",
        " - `loss` indica la funzione di costo o obiettivo (*loss function*) che rappresenta l'errore dell'uscita della rete rispetto all'uscita desiderata da ottimizzare (la corrispondenza tra le labels, in questo caso);\n",
        " - `metrics` indica i parametri di diagnostica desiderati sull'apprendimento della rete;"
      ],
      "metadata": {
        "id": "IRr8nUzYiXOy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Allenamento del modello\n"
      ],
      "metadata": {
        "id": "wb7iPXvhk9JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with timer() as training_time:\n",
        "  model.fit(train_data, epochs=epoch_count)"
      ],
      "metadata": {
        "id": "84sCIKKMlA5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il metodo `fit` fa partire l'allenamento della rete, andando ad utilizzare i parametri in ingresso:\n",
        " - `train_data` rappresenta le immagini in input e le labels per la supervisione;\n",
        " - `epochs` specifica il numero di iterazioni da eseguire sui dati prima di terminare l'allenamento;"
      ],
      "metadata": {
        "id": "-lJh6dBZmq41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test dei risultati"
      ],
      "metadata": {
        "id": "py4MLXEYm8J2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Valutazione degli input di test"
      ],
      "metadata": {
        "id": "UJaqaRhvnARP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with timer() as testing_time:\n",
        "  loss, accuracy = model.evaluate(test_data)\n",
        "print(\"Precisione test: {acc} ({acc_perc:.2f}%)\".format(acc=accuracy, acc_perc=accuracy*100))"
      ],
      "metadata": {
        "id": "Xbe-UOQAnEDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il metodo `evaluate` effettua i test e ritorna una coppia `loss, accuracy` che indicano rispettivamente l'errore e la precisione dei test."
      ],
      "metadata": {
        "id": "wfdffuCGnaYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparazione delle previsioni\n",
        "A questo punto non rimane che provare a passare alcuni dati (presi dagli input di test) e verificare la precisione delle previsioni "
      ],
      "metadata": {
        "id": "QcOYza9I6GTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = tf.keras.Sequential([model, tf.keras.layers.Softmax()]).predict(test_data)\n",
        "\n",
        "# caricamento delle labels di test per le comparazioni delle previsioni\n",
        "# può essere sostituito da qualsiasi dato affine al modello\n",
        "_, test_labels = tf.keras.datasets.mnist.load_data()[1]\n",
        "\n",
        "successful = 0\n",
        "for i in range(0, comparison_count):\n",
        "  if np.argmax(pred[i]) == test_labels[i]:\n",
        "    successful += 1\n",
        "  \n",
        "print(\"Risultato (previsioni giuste/totale): {successful}/{total}\".format(successful=successful, total=comparison_count))\n",
        "print(\"Precisione modello: {value:.2f}%\".format(value=100*successful/comparison_count))"
      ],
      "metadata": {
        "id": "8txN9vXBBRtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Valutazione dei tempi\n",
        "Ecco i tempi impiegati per le varie fasi:"
      ],
      "metadata": {
        "id": "f5ftVD3BnmD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dispositivo: \" + device_type + \" (\" + str(len(tf.config.list_logical_devices(device_type))) + \" unità)\")\n",
        "print(\"Tempo per il caricamento dei dati: \" + \"{t:.3f} s\".format(t=load_time()))\n",
        "print(\"Tempo per la compilazione del modello: \" + \"{t:.3f} s\".format(t=compilation_time()))\n",
        "print(\"Tempo per l'allenamento del modello: \" + \"{t:.3f} s\".format(t=training_time()))\n",
        "print(\"Tempo per il testing del modello: \" + \"{t:.3f} s\".format(t=testing_time()))"
      ],
      "metadata": {
        "id": "yAtxoikToHcQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}